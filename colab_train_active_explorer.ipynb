{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15c9367",
   "metadata": {},
   "source": [
    "# Colab-ready notebook: Train Active Explorer MNIST PPO (flat observations)\n",
    "# Cell 1: Title/description (Markdown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cc7f20",
   "metadata": {},
   "source": [
    "# Colab notebook\n",
    "\n",
    "This notebook trains the Active Explorer MNIST agent (PPO) using the same flat-observation style as your PC run. It clones the repo, installs dependencies, mounts Google Drive (optional), runs training (optionally resuming from a checkpoint in Drive), evaluates, and copies artifacts back to Drive for download.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Set Colab runtime to GPU (Runtime > Change runtime type > GPU)\n",
    "- [ ] (Optional) Upload any resume checkpoint (`ppo_pretrained.zip` or `ppo_final.zip`) into Google Drive\n",
    "- [ ] Run each cell in order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c7229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Install dependencies\n",
    "\n",
    "# Install core packages quietly. Adjust torch install if you need a specific CUDA version.\n",
    "!pip install -q stable-baselines3[extra] gymnasium torch torchvision opencv-python pandas seaborn scikit-learn tqdm\n",
    "\n",
    "# Verify versions and GPU\n",
    "import sys, torch\n",
    "print('Python', sys.version)\n",
    "print('Torch', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository and list files\n",
    "\n",
    "# Clone the repo (if you already uploaded the project to Drive you may skip cloning)\n",
    "!rm -rf decentralized-multiarm || true\n",
    "!git clone https://github.com/real-stanford/decentralized-multiarm.git\n",
    "\n",
    "# Show the active_explorer_mnist folder\n",
    "!ls -la decentralized-multiarm/active_explorer_mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1fba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (optional) and ensure repo exists\n",
    "import os\n",
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "print('If you want to persist models/logs, mount your Google Drive when prompted')\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Clone repository if it doesn't exist (useful when you open the notebook fresh)\n",
    "if not Path('/content/decentralized-multiarm').exists():\n",
    "    print('Cloning repository...')\n",
    "    os.system('git clone https://github.com/real-stanford/decentralized-multiarm.git')\n",
    "\n",
    "# Set workspace and default vars\n",
    "WORKDIR = '/content/decentralized-multiarm/active_explorer_mnist'\n",
    "if not Path(WORKDIR).exists():\n",
    "    raise FileNotFoundError(f\"Expected WORKDIR at {WORKDIR} — run the clone cell or upload your project to Drive and update WORKDIR.\")\n",
    "\n",
    "# change into workspace\n",
    "os.chdir(WORKDIR)\n",
    "print('Changed working directory to', os.getcwd())\n",
    "\n",
    "# Default parameters - edit these cells before running training\n",
    "RESUME_PATH = None  # e.g. '/content/drive/MyDrive/active_explorer_mnist/ppo_pretrained.zip'\n",
    "TIMESTEPS = 5000000  # set how many timesteps to run on Colab (e.g., 5e6)\n",
    "SAVE_DIR = './ppo_colab'\n",
    "SEED = 0\n",
    "print('WORKDIR', WORKDIR)\n",
    "print('RESUME_PATH', RESUME_PATH)\n",
    "print('TIMESTEPS', TIMESTEPS)\n",
    "print('SAVE_DIR', SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a060dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flat-observation wrapper note (no-op if env already returns flat obs)\n",
    "\n",
    "# The env in this repo already returns flat observations for SB3 MlpPolicy.\n",
    "# If you ever switch to a dict obs env, you can apply FlattenObservation wrapper:\n",
    "from gymnasium.wrappers import FlattenObservation\n",
    "print('FlattenObservation available')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8269ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training cell\n",
    "\n",
    "# Builds the command conditionally: include --resume-path only if RESUME_PATH is set\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "resume_flag = [\"--resume-path\", str(RESUME_PATH)] if RESUME_PATH else []\n",
    "cmd_list = [\n",
    "    'python3', 'train_explorer_ppo.py',\n",
    "    '--classifier', './mnist_cnn.pth',\n",
    "    '--timesteps', str(int(TIMESTEPS)),\n",
    "    '--save-path', SAVE_DIR,\n",
    "    '--seed', str(SEED),\n",
    "]\n",
    "# insert resume flag if present\n",
    "if resume_flag:\n",
    "    cmd_list[cmd_list.index('--save-path'):0]\n",
    "    cmd_list += resume_flag\n",
    "\n",
    "print('Running training command:')\n",
    "print(' '.join(cmd_list))\n",
    "\n",
    "# Run the training (this will display the tqdm output)\n",
    "# Use subprocess.run to stream output directly\n",
    "subprocess.run(cmd_list, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d722e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload helper cell — ways to get your classifier / resume model into Colab\n",
    "\n",
    "# Option A — place files in your Google Drive (recommended):\n",
    "# 1) Open https://drive.google.com in your browser\n",
    "# 2) Upload the files into a folder, e.g. /MyDrive/active_explorer_mnist/\n",
    "# 3) In the WORKDIR cell set RESUME_PATH='/content/drive/MyDrive/active_explorer_mnist/ppo_pretrained.zip'\n",
    "\n",
    "# Option B — upload directly to this Colab session (small files, ephemeral):\n",
    "from google.colab import files\n",
    "print('Use the file browser or the next cell to upload files directly to /content.')\n",
    "# Uncomment to run interactive upload (this will open a file picker):\n",
    "# uploaded = files.upload()\n",
    "# After upload, move files to the repo folder, e.g.:\n",
    "# import shutil\n",
    "# for fn in uploaded.keys():\n",
    "#     shutil.move(fn, WORKDIR)\n",
    "\n",
    "# Option C — download from a URL (if you host the files elsewhere):\n",
    "# !wget -O ./mnist_cnn.pth \"https://example.com/path/to/mnist_cnn.pth\"\n",
    "\n",
    "print('If you uploaded files via the Drive UI, set RESUME_PATH to the Drive path and run the training cell.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation + analysis cell\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Evaluate saved model (100 episodes) and generate plots\n",
    "MODEL_ZIP = Path(SAVE_DIR) / 'ppo_explorer.zip'\n",
    "if MODEL_ZIP.exists():\n",
    "    eval_cmd = [\n",
    "        'python3', 'test_policy_runner.py',\n",
    "        '--policy', 'saved',\n",
    "        '--saved-path', str(MODEL_ZIP),\n",
    "        '--num-episodes', '100',\n",
    "        '--output', './colab_results.csv',\n",
    "        '--classifier', './mnist_cnn.pth',\n",
    "        '--seed', str(SEED),\n",
    "    ]\n",
    "    print('Running evaluation:')\n",
    "    print(' '.join(eval_cmd))\n",
    "    subprocess.run(eval_cmd, check=True)\n",
    "    print('Analyzing results...')\n",
    "    subprocess.run(['python3', 'analyze_policy_results.py', './colab_results.csv', '--threshold', '0.90', '--out-dir', '.'], check=True)\n",
    "    # copy artifacts to Drive\n",
    "    dst_dir = Path('/content/drive/MyDrive/active_explorer_mnist')\n",
    "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for f in ['colab_results.csv', 'colab_results_confusion.png', 'colab_results_confidence_hist.png', 'colab_results_moves_vs_pixels.png']:\n",
    "        if Path(f).exists():\n",
    "            shutil.copy2(f, dst_dir / f)\n",
    "            print('Copied', f, 'to Drive')\n",
    "else:\n",
    "    print('Model zip not found, skipping evaluation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152247a1",
   "metadata": {},
   "source": [
    "# Final instructions\n",
    "\n",
    "1) In Colab: Runtime -> Change runtime type -> GPU, then run this notebook.\n",
    "\n",
    "2) If you have a BC/previous checkpoint from your PC, upload it to Google Drive and set `RESUME_PATH` to its Drive path (e.g., `/content/drive/MyDrive/active_explorer_mnist/ppo_pretrained.zip`) before running the training cell.\n",
    "\n",
    "3) The notebook copies the final `ppo_explorer.zip` and analysis artifacts to `/content/drive/MyDrive/active_explorer_mnist`. Use the Drive UI to download them to your PC.\n",
    "\n",
    "4) For direct downloads, small files may be downloaded with `from google.colab import files; files.download('path')`, but for large models Drive is recommended.\n",
    "\n",
    "5) If you want me to add a convolutional policy or reward-shaping example in the notebook, say so and I will update it.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
